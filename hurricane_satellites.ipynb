{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# hurricane-satellites\n",
        "This notebook is where the main processing occurs\n",
        "\n",
        "## Setup\n",
        "The following cells setup and run test to make sure things will run smoothly."
      ],
      "metadata": {
        "id": "ZoGfqJhozUHA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1UHK03axkyf"
      },
      "outputs": [],
      "source": [
        "%cd ~/\n",
        "!git clone https://github.com/hammad93/hurricane-satellites.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r hurricane-satellites/requirements.txt"
      ],
      "metadata": {
        "id": "iu6xKrAvy1qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html#environment-variables\n",
        "vars = [\"EUMETSAT_PASS\", \"EUMETSAT_SECRET\", \"BASE64_SSH_GEOSERVER\", \"HOST_SSH\", \"USER_SSH\"]\n",
        "if None in [os.getenv(env) for env in vars] :\n",
        "  from google.colab import userdata\n",
        "  for var in vars :\n",
        "    os.environ[var] = userdata.get(var)"
      ],
      "metadata": {
        "id": "rQIC13t6zCPV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Satellite Classes\n",
        "Utilizing software design patterns, we will create a satellite object based on a predefined satellite class for each satellite we are processing."
      ],
      "metadata": {
        "id": "Fzm8iOUTzyi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ~/hurricane-satellites\n",
        "import satellite\n",
        "import goes_east\n",
        "import goes_west\n",
        "import h8\n",
        "import msg_0\n",
        "import msg_io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rwR7SPLzMTC",
        "outputId": "68bff38f-1f0c-41a3-d355-175e86c1aa54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/hurricane-satellites\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Your satellite sources list\n",
        "satellites = [\n",
        "    goes_east.GOESEastDataSource(),\n",
        "    goes_west.GOESWestDataSource(),\n",
        "    msg_0.MSG0DegreeDataSource(),\n",
        "    msg_io.MSGIndianOceanDataSource(),\n",
        "    h8.Himawari8DataSource()\n",
        "]\n",
        "\n",
        "def fetch_data_for_satellite(satellite, file_prefix):\n",
        "    \"\"\"\n",
        "    Wrapper function to call getRecentData on a satellite object.\n",
        "    \"\"\"\n",
        "    satellite.getRecentData(file_prefix=file_prefix)\n",
        "\n",
        "def main():\n",
        "    prefix = f\"[{int(time.time())}]\"\n",
        "    # Use ThreadPoolExecutor to run getRecentData concurrently for each satellite\n",
        "    with ThreadPoolExecutor(max_workers=len(satellites)) as executor:\n",
        "        # Schedule the executions\n",
        "        futures = [executor.submit(fetch_data_for_satellite, satellite, prefix) for satellite in satellites]\n",
        "\n",
        "        # Optionally, wait for all futures to complete and handle results/errors\n",
        "        for future in futures:\n",
        "            try:\n",
        "                # Result handling here if needed\n",
        "                future.result()  # This will raise exceptions if any occurred\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "main()"
      ],
      "metadata": {
        "id": "Yxgg_ET6zmxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract and Download"
      ],
      "metadata": {
        "id": "2kjQIWF2E7dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "satellites"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt0nq7roE-1v",
        "outputId": "be6515b1-3803-4a8a-bdd5-523bc1dbf697"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<goes_east.GOESEastDataSource at 0x78b7afbb9180>,\n",
              " <goes_west.GOESWestDataSource at 0x78b76c40fdc0>,\n",
              " <msg_0.MSG0DegreeDataSource at 0x78b76c40ffa0>,\n",
              " <msg_io.MSGIndianOceanDataSource at 0x78b76c189c90>,\n",
              " <h8.Himawari8DataSource at 0x78b76c189c30>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for satellite in satellites :\n",
        "    satellite.toNetCDF()"
      ],
      "metadata": {
        "id": "D8z2H9TFFC8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload"
      ],
      "metadata": {
        "id": "jAX1p8dhoF62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "with open('key.pem', 'wb') as f:\n",
        "  f.write(base64.b64decode(userdata.get('BASE64_SSH_GEOSERVER')))"
      ],
      "metadata": {
        "id": "vHojW53QoFO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "upload_queue = []\n",
        "for f in os.listdir():\n",
        "    if f[-2:] == \"nc\": # NetCDF file extension\n",
        "        upload_queue.append(f)\n",
        "print(upload_queue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv4HUsnwoQ55",
        "outputId": "2bca7cab-5613-4969-b257-0fdbf5d19a53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[1713331543][H8]_2_combined_image_greyscale.nc', '[1713331543][H8]_3_combined_image_greyscale.nc', '[1713331543][GOES-18]_GOES18-ABI-FD-GEOCOLOR-10848x10848.nc', '[1713331543][H8]_1_combined_image_greyscale.nc', '[1713331543][GOES-16]_GOES16-ABI-FD-GEOCOLOR-10848x10848.nc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysftp\n",
        "cnopts = pysftp.CnOpts()\n",
        "cnopts.hostkeys = None\n",
        "\n",
        "with pysftp.Connection(host=os.getenv('HOST_SSH'), username=os.getenv('USER_SSH'), private_key=\"key.pem\", cnopts=cnopts) as sftp:\n",
        "    with sftp.cd('/home/bitnami/hurricane-server/wms_data/'):\n",
        "      for upload in upload_queue:\n",
        "          print(f\"Uploading {upload} . . .\")\n",
        "          sftp.put(upload)\n"
      ],
      "metadata": {
        "id": "hDSblKCForLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix\n",
        "This code is here for reference and can be safely removed."
      ],
      "metadata": {
        "id": "KJqfPGv-1mM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blAZWghjnpc3",
        "outputId": "009ae4d2-0a9f-454b-ddac-732965f17250"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mdiff --git a/msg_0.py b/msg_0.py\u001b[m\n",
            "\u001b[1mindex d1168d4..d7550da 100644\u001b[m\n",
            "\u001b[1m--- a/msg_0.py\u001b[m\n",
            "\u001b[1m+++ b/msg_0.py\u001b[m\n",
            "\u001b[36m@@ -16,7 +16,7 @@\u001b[m \u001b[mclass MSG0DegreeDataSource(satellite.DataSource):\u001b[m\n",
            "         \"\"\"\u001b[m\n",
            "         self.recent_file_prefix = file_prefix\u001b[m\n",
            "         credentials = (self.consumer_key, self.consumer_secret)\u001b[m\n",
            "\u001b[31m-        token = eumdac.AccessToken(credentials)\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m        token = eumdac.AccessToken(credentials, cache=False)\u001b[m\n",
            " \u001b[m\n",
            "         print(f\"This token '{token}' expires {token.expiration}\")\u001b[m\n",
            " \u001b[m\n",
            "\u001b[36m@@ -63,7 +63,7 @@\u001b[m \u001b[mclass MSG0DegreeDataSource(satellite.DataSource):\u001b[m\n",
            "         # output to NetCDF\u001b[m\n",
            "         output = scn.load(scn.available_dataset_names(), upper_right_corner='NE')\u001b[m\n",
            "         scn.save_datasets(\u001b[m\n",
            "\u001b[31m-            filename=f\"{self.recent_file_prefix}[{self.id}]\",\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m            filename=f\"{self.recent_file_prefix}[{self.id}].nc\",\u001b[m\n",
            "             writer=\"cf\",\u001b[m\n",
            "             groups={\u001b[m\n",
            "                 'default': filter(lambda x: x!='HRV', scn.available_dataset_names()),\u001b[m\n",
            "\u001b[1mdiff --git a/msg_io.py b/msg_io.py\u001b[m\n",
            "\u001b[1mindex 652fc92..53c5317 100644\u001b[m\n",
            "\u001b[1m--- a/msg_io.py\u001b[m\n",
            "\u001b[1m+++ b/msg_io.py\u001b[m\n",
            "\u001b[36m@@ -16,7 +16,7 @@\u001b[m \u001b[mclass MSGIndianOceanDataSource(satellite.DataSource):\u001b[m\n",
            "         \"\"\"\u001b[m\n",
            "         self.recent_file_prefix = file_prefix\u001b[m\n",
            "         credentials = (self.consumer_key, self.consumer_secret)\u001b[m\n",
            "\u001b[31m-        token = eumdac.AccessToken(credentials)\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m        token = eumdac.AccessToken(credentials, cache=False)\u001b[m\n",
            " \u001b[m\n",
            "         print(f\"This token '{token}' expires {token.expiration}\")\u001b[m\n",
            " \u001b[m\n",
            "\u001b[36m@@ -63,7 +63,7 @@\u001b[m \u001b[mclass MSGIndianOceanDataSource(satellite.DataSource):\u001b[m\n",
            "         # output to NetCDF\u001b[m\n",
            "         output = scn.load(scn.available_dataset_names(), upper_right_corner='NE')\u001b[m\n",
            "         scn.save_datasets(\u001b[m\n",
            "\u001b[31m-            filename=f\"{self.recent_file_prefix}[{self.id}]\",\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m            filename=f\"{self.recent_file_prefix}[{self.id}].nc\",\u001b[m\n",
            "             writer=\"cf\",\u001b[m\n",
            "             groups={\u001b[m\n",
            "                 'default': filter(lambda x: x!='HRV', scn.available_dataset_names()),\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqc4DlUDyBPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}